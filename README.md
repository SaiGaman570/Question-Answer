# ğŸ“„ QNAdoc â€” Document QA Chatbot

A Streamlit-based chatbot that allows users to upload a PDF and ask natural language questions. Powered by LangChain, HuggingFace embeddings, Groq LLM, and Chroma vector store.

## âœ¨ Features

- ğŸ“¥ Upload and process any PDF document
- ğŸ§  Contextual question answering using embedded document chunks
- ğŸ’¬ Real-time responses via Groq's `llama3-70b-8192` model
- ğŸ” Vector-based retrieval using HuggingFace + Chroma
- ğŸ› ï¸ Modular architecture with customizable embedding, chunking, and model layers

## ğŸ“ Project Structure

```text
â”œâ”€â”€ app.py             # Streamlit interface for document upload and QA
â”œâ”€â”€ docqa.py           # PDF loader, retriever setup, and QA logic
â”œâ”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ .env               # Environment file with Groq API key and model info
```

## âš™ï¸ Setup Instructions

1. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Set environment variables**  
   Create a `.env` file:
   ```env
   GROQ_API_KEY=your_groq_api_key_here
   ```

3. **Run the Streamlit app**
   ```bash
   streamlit run app.py
   ```

## ğŸ“š How It Works

1. User uploads a PDF file.
2. PDF is split into chunks using `CharacterTextSplitter`.
3. Chunks are embedded using `HuggingFaceEmbeddings`.
4. Chroma vector store retrieves relevant chunks based on user question.
5. A prompt is constructed with the question and context.
6. Groqâ€™s LLM responds with an answer.

## ğŸ’¡ Example Interaction

```
User: What are the key findings from the document?
ğŸ¤– AI: The document highlights three main findings...
```

## ğŸ™Œ Acknowledgments

Built with:
- [LangChain](https://www.langchain.com/)
- [HuggingFace Embeddings](https://www.sbert.net/)
- [Chroma](https://www.trychroma.com/)
- [Groq LLM](https://groq.com/)
- [Streamlit](https://streamlit.io/)
